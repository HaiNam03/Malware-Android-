import pandas as pd
import numpy as np
from gensim.models.doc2vec import TaggedDocument, Doc2Vec
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
from sklearn.metrics import confusion_matrix
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.model_selection import train_test_split
import warnings
from sklearn import utils
import pickle
import re

warnings.filterwarnings('ignore')

df = pd.read_csv('dataset0.csv')
df.drop(['permission', 'intent'],axis=1,inplace=True)
df.drop_duplicates(inplace=True)
print(df)
df.dropna(inplace=True,axis=0)
print(df)

# stop_words = set(stopwords.words('english'))
# tokenized_docs = [nltk.word_tokenize(text.lower()) for text in df['APIcall']]
# preprocessed_doc = [[word for word in tokens if word.isalnum() and word not in stop_words] for tokens in tokenized_docs]
# def preprocess_text(text):
#     text = re.sub(r'http\S+', '', text)
#     text = re.sub(r'[^\w\s]', '', text)
#     text = text.lower()
#     text = re.sub(r'\s+', ' ', text).strip()
#     return text
# df['APIcall']=df['APIcall'].apply(preprocess_text)

def label_sentences(corpus, label_type):
    labeled = []
    for i, v in enumerate(corpus):
        label = label_type + "_" + str(i)
        labeled.append(TaggedDocument(v.split(),[label]))
    return labeled

x_train, x_test, Y_train, Y_test =train_test_split(df['APIcall'], df['label'], test_size=0.2, random_state=42)
print(x_train[:6])

# train_tagged = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(x_train)]
#
# doc2vec_model = Doc2Vec(vector_size= 100, window=5, min_count= 1, workers=4, epochs=100)
# doc2vec_model.build_vocab(train_tagged)
# doc2vec_model.train(train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)
#
# X_train = [doc2vec_model.dv[tag] for tag in range(len(x_train))]
# X_test = [doc2vec_model.dv[tag] for tag in range(len(x_test))]
# print (X_train)
# print (X_test)
x_train = label_sentences(x_train, "Train")
x_test = label_sentences(x_test, "Test")
all_data = x_train + x_test
doc2vec_model = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)
doc2vec_model.build_vocab([x for x in all_data])

for epoch in range(30):
    doc2vec_model.train(utils.shuffle([x for x in all_data]), total_examples=len(all_data), epochs=1)
    doc2vec_model.alpha -=0.002
    doc2vec_model.min_alpha = doc2vec_model.alpha

def get_vector(model, corpus_size, vector_size, vector_type):
    vectors = np.zeros((corpus_size, vector_size))
    for i in range(0, corpus_size):
        prefix = vector_type + "_" + str(i)
        vectors[i]= model.docvecs[prefix]
    return vectors

X_train = get_vector(doc2vec_model, len(x_train), 300, "Train")
X_test = get_vector(doc2vec_model, len(x_test), 300, "Test")
print (X_train[:5])
print (X_test[:5])






rf_model = RandomForestClassifier(n_estimators=60)
rf_model.fit(X_train, Y_train)
pickle.dump(rf_model,open('rf2.pkl','wb'))
predictions_rf = rf_model.predict(X_test)
tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(y_true=Y_test, y_pred=predictions_rf).ravel()
accuracy_rf = (tp_rf + tn_rf) / (tp_rf + tn_rf + fp_rf + fn_rf)
precision_rf = tp_rf / (tp_rf + fp_rf)
recall_rf = tp_rf / (tp_rf + fn_rf)
print("accuracy_rf --> ", accuracy_rf)
print("precision_rf --> ", precision_rf)
print("recall_rf --> ", recall_rf)

svm_model = svm.LinearSVC()
svm_model.fit(X_train, Y_train)
pickle.dump(svm_model,open('svm2.pkl','wb'))
predictions_svm = svm_model.predict(X_test)
tn_svm, fp_svm, fn_svm, tp_svm = confusion_matrix(y_true=Y_test, y_pred=predictions_svm).ravel()
accuracy_svm = (tp_svm + tn_svm) / (tp_svm + tn_svm + fp_svm + fn_svm)
precision_svm = tp_svm / (tp_svm + fp_svm)
recall_svm = tp_svm / (tp_svm + fn_svm)
print("accuracy_svm --> ", accuracy_svm)
print("precision_svm --> ", precision_svm)
print("recall_svm --> ", recall_svm)

# Decision Tree
dt_model = tree.DecisionTreeClassifier()
dt_model.fit(X_train, Y_train)
pickle.dump(svm_model,open('dt2.pkl','wb'))
predictions_dt = dt_model.predict(X_test)
tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(y_true=Y_test, y_pred=predictions_dt).ravel()
accuracy_dt = (tp_dt + tn_dt) / (tp_dt + tn_dt + fp_dt + fn_dt)
precision_dt = tp_dt / (tp_dt + fp_dt)
recall_dt = tp_dt / (tp_dt + fn_dt)
print("accuracy_dt --> ", accuracy_dt)
print("precision_dt --> ", precision_dt)
print("recall_dt --> ", recall_dt)

# AdaBoost
ab_model = AdaBoostClassifier()
ab_model.fit(X_train, Y_train)
pickle.dump(svm_model,open('ab2.pkl','wb'))
predictions_ab = ab_model.predict(X_test)
tn_ab, fp_ab, fn_ab, tp_ab = confusion_matrix(y_true=Y_test, y_pred=predictions_ab).ravel()
accuracy_ab = (tp_ab + tn_ab) / (tp_ab + tn_ab + fp_ab + fn_ab)
precision_ab = tp_ab / (tp_ab + fp_ab)
recall_ab = tp_ab / (tp_ab + fn_ab)
print("accuracy_ab --> ", accuracy_ab)
print("precision_ab --> ", precision_ab)
print("recall_ab --> ", recall_ab)

# Gaussian Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, Y_train)
pickle.dump(svm_model,open('gnb2.pkl','wb'))
predictions_nb = nb_model.predict(X_test)
tn_nb, fp_nb, fn_nb, tp_nb = confusion_matrix(y_true=Y_test, y_pred=predictions_nb).ravel()
accuracy_nb = (tp_nb + tn_nb) / (tp_nb + tn_nb + fp_nb + fn_nb)
precision_nb = tp_nb / (tp_nb + fp_nb)
recall_nb = tp_nb / (tp_nb + fn_nb)
print("accuracy_nb --> ", accuracy_nb)
print("precision_nb --> ", precision_nb)
print("recall_nb --> ", recall_nb)

# Neural Network_MLPClassifier
MLPCLASS_model = MLPClassifier(alpha=1)
MLPCLASS_model.fit(X_train, Y_train)
pickle.dump(svm_model,open('mlp2.pkl','wb'))
predictions_MLPCLASS = MLPCLASS_model.predict(X_test)
tn_MLPCLASS, fp_MLPCLASS, fn_MLPCLASS, tp_MLPCLASS = confusion_matrix(y_true=Y_test, y_pred=predictions_MLPCLASS).ravel()
accuracy_MLPCLASS = (tp_MLPCLASS + tn_MLPCLASS) / (tp_MLPCLASS + tn_MLPCLASS + fp_MLPCLASS + fn_MLPCLASS)
precision_MLPCLASS = tp_MLPCLASS / (tp_MLPCLASS + fp_MLPCLASS)
recall_MLPCLASS = tp_MLPCLASS / (tp_MLPCLASS + fn_MLPCLASS)
print("accuracy_MLPCLASS --> ", accuracy_MLPCLASS)
print("precision_MLPCLASS --> ", precision_MLPCLASS)
print("recall_MLPCLASS --> ", recall_MLPCLASS)

